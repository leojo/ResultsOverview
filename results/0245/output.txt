Sender: LSF System <lsfadmin@lo-s4-036>
Subject: Job 575282: <python main.py results/0245> in cluster <leonhard> Exited

Job <python main.py results/0245> was submitted from host <lo-login-01> by user <leoj> in cluster <leonhard> at Fri Jul 27 14:53:52 2018
Job was executed on host(s) <4*lo-s4-036>, in queue <gpu.24h>, as user <leoj> in cluster <leonhard> at Fri Jul 27 14:53:58 2018
</cluster/home/leoj> was used as the home directory.
</cluster/home/leoj/sandbox> was used as the working directory.
Started at Fri Jul 27 14:53:58 2018
Terminated at Fri Jul 27 18:20:23 2018
Results reported at Fri Jul 27 18:20:23 2018

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py results/0245
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   14315.25 sec.
    Max Memory :                                 55110 MB
    Average Memory :                             15638.48 MB
    Total Requested Memory :                     128000.00 MB
    Delta Memory :                               72890.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                27
    Run time :                                   12412 sec.
    Turnaround time :                            12391 sec.

The output (if any) follows:

WARNING:tensorflow:From /cluster/home/leoj/.virtualenvs/mp/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Use the retry module or similar alternatives.
WARNING:tensorflow:From /cluster/home/leoj/.virtualenvs/mp/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.
Instructions for updating:
`NHWC` for data_format is deprecated, use `NWC` instead
2018-07-27 15:03:10.077182: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-07-27 15:03:10.412774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:04:00.0
totalMemory: 10.92GiB freeMemory: 10.76GiB
2018-07-27 15:03:10.412818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-07-27 15:03:11.433778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-07-27 15:03:11.433873: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-07-27 15:03:11.433890: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-07-27 15:03:11.434417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10417 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0, compute capability: 6.1)
  0%|          | 0/600 [00:00<?, ?it/s]Loss: 0.0130, L2-loss: 0.0130, KL: 0.0323, Learning rate: 0.0001:   0%|          | 0/600 [00:36<?, ?it/s]Loss: 0.0130, L2-loss: 0.0130, KL: 0.0323, Learning rate: 0.0001:   0%|          | 1/600 [00:36<6:02:57, 36.36s/it]Loss: 0.0128, L2-loss: 0.0128, KL: 0.0715, Learning rate: 0.0001:   0%|          | 1/600 [01:08<11:22:47, 68.39s/it]Loss: 0.0128, L2-loss: 0.0128, KL: 0.0715, Learning rate: 0.0001:   0%|          | 2/600 [01:08<5:40:49, 34.20s/it] Loss: 0.0129, L2-loss: 0.0129, KL: 0.0328, Learning rate: 0.0001:   0%|          | 2/600 [01:41<8:25:27, 50.72s/it]Loss: 0.0129, L2-loss: 0.0129, KL: 0.0328, Learning rate: 0.0001:   0%|          | 3/600 [01:41<5:36:24, 33.81s/it]Loss: 0.0128, L2-loss: 0.0128, KL: 0.0207, Learning rate: 0.0001:   0%|          | 3/600 [02:14<7:24:46, 44.70s/it]Loss: 0.0128, L2-loss: 0.0128, KL: 0.0207, Learning rate: 0.0001:   1%|          | 4/600 [02:14<5:33:01, 33.53s/it]Loss: 0.0126, L2-loss: 0.0126, KL: 0.0201, Learning rate: 0.0001:   1%|          | 4/600 [02:45<6:49:56, 41.27s/it]Loss: 0.0126, L2-loss: 0.0126, KL: 0.0201, Learning rate: 0.0001:   1%|          | 5/600 [02:45<5:27:24, 33.02s/it]Loss: 0.0127, L2-loss: 0.0127, KL: 0.0201, Learning rate: 0.0001:   1%|          | 5/600 [03:16<6:29:47, 39.31s/it]Loss: 0.0127, L2-loss: 0.0127, KL: 0.0201, Learning rate: 0.0001:   1%|1         | 6/600 [03:16<5:24:16, 32.76s/it]Loss: 0.0130, L2-loss: 0.0130, KL: 0.0200, Learning rate: 0.0001:   1%|1         | 6/600 [03:49<6:17:51, 38.17s/it]Loss: 0.0130, L2-loss: 0.0130, KL: 0.0200, Learning rate: 0.0001:   1%|1         | 7/600 [03:49<5:23:20, 32.72s/it]Loss: 0.0129, L2-loss: 0.0129, KL: 0.0200, Learning rate: 0.0001:   1%|1         | 7/600 [04:22<6:10:02, 37.44s/it]Loss: 0.0129, L2-loss: 0.0129, KL: 0.0200, Learning rate: 0.0001:   1%|1         | 8/600 [04:22<5:23:14, 32.76s/it]Loss: 0.0129, L2-loss: 0.0128, KL: 0.0200, Learning rate: 0.0001:   1%|1         | 8/600 [04:55<6:03:56, 36.89s/it]Loss: 0.0129, L2-loss: 0.0128, KL: 0.0200, Learning rate: 0.0001:   2%|1         | 9/600 [04:55<5:22:57, 32.79s/it]Loss: 0.0127, L2-loss: 0.0127, KL: 0.0200, Learning rate: 0.0001:   2%|1         | 9/600 [05:27<5:58:57, 36.44s/it]Loss: 0.0127, L2-loss: 0.0127, KL: 0.0200, Learning rate: 0.0001:   2%|1         | 10/600 [05:27<5:22:30, 32.80s/it]Loss: 0.0128, L2-loss: 0.0128, KL: 0.0201, Learning rate: 0.0001:   2%|1         | 10/600 [06:01<5:55:05, 36.11s/it]Loss: 0.0128, L2-loss: 0.0128, KL: 0.0201, Learning rate: 0.0001:   2%|1         | 11/600 [06:01<5:22:15, 32.83s/it]Loss: 0.0128, L2-loss: 0.0128, KL: 0.0207, Learning rate: 0.0001:   2%|1         | 11/600 [06:34<5:51:38, 35.82s/it]Loss: 0.0128, L2-loss: 0.0128, KL: 0.0207, Learning rate: 0.0001:   2%|2         | 12/600 [06:34<5:21:47, 32.84s/it]Loss: 0.0125, L2-loss: 0.0125, KL: 0.1054, Learning rate: 0.0001:   2%|2         | 12/600 [07:06<5:48:38, 35.58s/it]Loss: 0.0125, L2-loss: 0.0125, KL: 0.1054, Learning rate: 0.0001:   2%|2         | 13/600 [07:06<5:21:16, 32.84s/it]Loss: 0.0119, L2-loss: 0.0117, KL: 1.9707, Learning rate: 0.0001:   2%|2         | 13/600 [07:39<5:45:58, 35.36s/it]Loss: 0.0119, L2-loss: 0.0117, KL: 1.9707, Learning rate: 0.0001:   2%|2         | 14/600 [07:39<5:20:43, 32.84s/it]Loss: 0.0116, L2-loss: 0.0112, KL: 3.4567, Learning rate: 0.0001:   2%|2         | 14/600 [08:12<5:43:37, 35.18s/it]Loss: 0.0116, L2-loss: 0.0112, KL: 3.4567, Learning rate: 0.0001:   2%|2         | 15/600 [08:12<5:20:10, 32.84s/it]Loss: 0.0112, L2-loss: 0.0108, KL: 4.0321, Learning rate: 0.0001:   2%|2         | 15/600 [08:45<5:41:29, 35.02s/it]Loss: 0.0112, L2-loss: 0.0108, KL: 4.0321, Learning rate: 0.0001:   3%|2         | 16/600 [08:45<5:19:36, 32.84s/it]Loss: 0.0112, L2-loss: 0.0107, KL: 4.3819, Learning rate: 0.0001:   3%|2         | 16/600 [09:18<5:39:30, 34.88s/it]Loss: 0.0112, L2-loss: 0.0107, KL: 4.3819, Learning rate: 0.0001:   3%|2         | 17/600 [09:18<5:18:59, 32.83s/it]Loss: 0.0109, L2-loss: 0.0104, KL: 4.5741, Learning rate: 0.0001:   3%|2         | 17/600 [09:50<5:37:45, 34.76s/it]Loss: 0.0109, L2-loss: 0.0104, KL: 4.5741, Learning rate: 0.0001:   3%|3         | 18/600 [09:50<5:18:27, 32.83s/it]Loss: 0.0107, L2-loss: 0.0102, KL: 4.7682, Learning rate: 0.0001:   3%|3         | 18/600 [10:24<5:36:22, 34.68s/it]Loss: 0.0107, L2-loss: 0.0102, KL: 4.7682, Learning rate: 0.0001:   3%|3         | 19/600 [10:24<5:18:06, 32.85s/it]Loss: 0.0108, L2-loss: 0.0103, KL: 4.9688, Learning rate: 0.0001:   3%|3         | 19/600 [10:56<5:34:45, 34.57s/it]Loss: 0.0108, L2-loss: 0.0103, KL: 4.9688, Learning rate: 0.0001:   3%|3         | 20/600 [10:56<5:17:28, 32.84s/it]Loss: 0.0106, L2-loss: 0.0101, KL: 5.0297, Learning rate: 0.0001:   3%|3         | 20/600 [11:29<5:33:17, 34.48s/it]Loss: 0.0106, L2-loss: 0.0101, KL: 5.0297, Learning rate: 0.0001:   4%|3         | 21/600 [11:29<5:16:52, 32.84s/it]Loss: 0.0105, L2-loss: 0.0100, KL: 5.2092, Learning rate: 0.0001:   4%|3         | 21/600 [12:02<5:31:59, 34.40s/it]Loss: 0.0105, L2-loss: 0.0100, KL: 5.2092, Learning rate: 0.0001:   4%|3         | 22/600 [12:02<5:16:20, 32.84s/it]Loss: 0.0104, L2-loss: 0.0099, KL: 5.2559, Learning rate: 0.0001:   4%|3         | 22/600 [12:35<5:30:43, 34.33s/it]Loss: 0.0104, L2-loss: 0.0099, KL: 5.2559, Learning rate: 0.0001:   4%|3         | 23/600 [12:35<5:15:47, 32.84s/it]Loss: 0.0105, L2-loss: 0.0100, KL: 5.3478, Learning rate: 0.0001:   4%|3         | 23/600 [13:07<5:29:27, 34.26s/it]Loss: 0.0105, L2-loss: 0.0100, KL: 5.3478, Learning rate: 0.0001:   4%|4         | 24/600 [13:07<5:15:11, 32.83s/it]Loss: 0.0105, L2-loss: 0.0099, KL: 5.4561, Learning rate: 0.0001:   4%|4         | 24/600 [13:40<5:28:15, 34.19s/it]Loss: 0.0105, L2-loss: 0.0099, KL: 5.4561, Learning rate: 0.0001:   4%|4         | 25/600 [13:40<5:14:34, 32.83s/it]Loss: 0.0103, L2-loss: 0.0098, KL: 5.4690, Learning rate: 0.0001:   4%|4         | 25/600 [14:12<5:26:55, 34.11s/it]Loss: 0.0103, L2-loss: 0.0098, KL: 5.4690, Learning rate: 0.0001:   4%|4         | 26/600 [14:12<5:13:48, 32.80s/it]Loss: 0.0103, L2-loss: 0.0097, KL: 5.5375, Learning rate: 0.0001:   4%|4         | 26/600 [14:45<5:25:46, 34.05s/it]Loss: 0.0103, L2-loss: 0.0097, KL: 5.5375, Learning rate: 0.0001:   4%|4         | 27/600 [14:45<5:13:09, 32.79s/it]Loss: 0.0103, L2-loss: 0.0097, KL: 5.6676, Learning rate: 0.0001:   4%|4         | 27/600 [15:18<5:24:52, 34.02s/it]Loss: 0.0103, L2-loss: 0.0097, KL: 5.6676, Learning rate: 0.0001:   5%|4         | 28/600 [15:18<5:12:43, 32.80s/it]Loss: 0.0103, L2-loss: 0.0097, KL: 5.7105, Learning rate: 1e-05:   5%|4         | 28/600 [15:51<5:23:53, 33.98s/it] Loss: 0.0103, L2-loss: 0.0097, KL: 5.7105, Learning rate: 1e-05:   5%|4         | 29/600 [15:51<5:12:10, 32.80s/it]Loss: 0.0102, L2-loss: 0.0096, KL: 5.7805, Learning rate: 1e-05:   5%|4         | 29/600 [16:24<5:22:54, 33.93s/it]Loss: 0.0102, L2-loss: 0.0096, KL: 5.7805, Learning rate: 1e-05:   5%|5         | 30/600 [16:24<5:11:36, 32.80s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 5.7202, Learning rate: 1e-05:   5%|5         | 30/600 [16:56<5:22:00, 33.90s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 5.7202, Learning rate: 1e-05:   5%|5         | 31/600 [16:56<5:11:04, 32.80s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 5.7520, Learning rate: 1e-05:   5%|5         | 31/600 [17:29<5:21:12, 33.87s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 5.7520, Learning rate: 1e-05:   5%|5         | 32/600 [17:29<5:10:36, 32.81s/it]Loss: 0.0100, L2-loss: 0.0095, KL: 5.8066, Learning rate: 1e-05:   5%|5         | 32/600 [18:02<5:20:22, 33.84s/it]Loss: 0.0100, L2-loss: 0.0095, KL: 5.8066, Learning rate: 1e-05:   6%|5         | 33/600 [18:02<5:10:07, 32.82s/it]Loss: 0.0102, L2-loss: 0.0096, KL: 5.9304, Learning rate: 1e-05:   6%|5         | 33/600 [18:35<5:19:28, 33.81s/it]Loss: 0.0102, L2-loss: 0.0096, KL: 5.9304, Learning rate: 1e-05:   6%|5         | 34/600 [18:35<5:09:32, 32.81s/it]Loss: 0.0102, L2-loss: 0.0096, KL: 5.8707, Learning rate: 1e-05:   6%|5         | 34/600 [19:08<5:18:41, 33.78s/it]Loss: 0.0102, L2-loss: 0.0096, KL: 5.8707, Learning rate: 1e-05:   6%|5         | 35/600 [19:08<5:09:02, 32.82s/it]Loss: 0.0102, L2-loss: 0.0096, KL: 5.9779, Learning rate: 1e-05:   6%|5         | 35/600 [19:41<5:17:49, 33.75s/it]Loss: 0.0102, L2-loss: 0.0096, KL: 5.9779, Learning rate: 1e-05:   6%|6         | 36/600 [19:41<5:08:26, 32.81s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 5.9150, Learning rate: 1e-05:   6%|6         | 36/600 [20:13<5:16:57, 33.72s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 5.9150, Learning rate: 1e-05:   6%|6         | 37/600 [20:13<5:07:50, 32.81s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 5.9640, Learning rate: 1e-05:   6%|6         | 37/600 [20:46<5:16:10, 33.70s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 5.9640, Learning rate: 1e-05:   6%|6         | 38/600 [20:46<5:07:18, 32.81s/it]Loss: 0.0101, L2-loss: 0.0096, KL: 5.9782, Learning rate: 1e-05:   6%|6         | 38/600 [21:19<5:15:28, 33.68s/it]Loss: 0.0101, L2-loss: 0.0096, KL: 5.9782, Learning rate: 1e-05:   6%|6         | 39/600 [21:19<5:06:50, 32.82s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.0198, Learning rate: 1e-05:   6%|6         | 39/600 [21:52<5:14:42, 33.66s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.0198, Learning rate: 1e-05:   7%|6         | 40/600 [21:52<5:06:18, 32.82s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 5.8994, Learning rate: 1e-05:   7%|6         | 40/600 [22:25<5:13:58, 33.64s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 5.8994, Learning rate: 1e-05:   7%|6         | 41/600 [22:25<5:05:46, 32.82s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 5.9880, Learning rate: 1e-05:   7%|6         | 41/600 [22:58<5:13:18, 33.63s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 5.9880, Learning rate: 1e-05:   7%|7         | 42/600 [22:58<5:05:17, 32.83s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 5.9616, Learning rate: 1e-05:   7%|7         | 42/600 [23:31<5:12:36, 33.61s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 5.9616, Learning rate: 1e-05:   7%|7         | 43/600 [23:31<5:04:47, 32.83s/it]Loss: 0.0102, L2-loss: 0.0096, KL: 6.0037, Learning rate: 1e-05:   7%|7         | 43/600 [24:04<5:11:56, 33.60s/it]Loss: 0.0102, L2-loss: 0.0096, KL: 6.0037, Learning rate: 1e-05:   7%|7         | 44/600 [24:04<5:04:18, 32.84s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.0135, Learning rate: 1e-05:   7%|7         | 44/600 [24:37<5:11:14, 33.59s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.0135, Learning rate: 1e-05:   8%|7         | 45/600 [24:37<5:03:46, 32.84s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0168, Learning rate: 1e-05:   8%|7         | 45/600 [25:10<5:10:31, 33.57s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0168, Learning rate: 1e-05:   8%|7         | 46/600 [25:10<5:03:13, 32.84s/it]Loss: 0.0102, L2-loss: 0.0096, KL: 6.0737, Learning rate: 1e-05:   8%|7         | 46/600 [25:42<5:09:39, 33.54s/it]Loss: 0.0102, L2-loss: 0.0096, KL: 6.0737, Learning rate: 1e-05:   8%|7         | 47/600 [25:42<5:02:31, 32.82s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.0453, Learning rate: 1e-05:   8%|7         | 47/600 [26:15<5:09:01, 33.53s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.0453, Learning rate: 1e-05:   8%|8         | 48/600 [26:15<5:02:01, 32.83s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0275, Learning rate: 1e-05:   8%|8         | 48/600 [26:48<5:08:20, 33.52s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0275, Learning rate: 1e-05:   8%|8         | 49/600 [26:48<5:01:30, 32.83s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0646, Learning rate: 1e-05:   8%|8         | 49/600 [27:21<5:07:38, 33.50s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0646, Learning rate: 1e-05:   8%|8         | 50/600 [27:21<5:00:56, 32.83s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0536, Learning rate: 1e-05:   8%|8         | 50/600 [27:53<5:06:50, 33.47s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0536, Learning rate: 1e-05:   8%|8         | 51/600 [27:53<5:00:16, 32.82s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0723, Learning rate: 1e-05:   8%|8         | 51/600 [28:26<5:06:10, 33.46s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0723, Learning rate: 1e-05:   9%|8         | 52/600 [28:26<4:59:44, 32.82s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0860, Learning rate: 1e-06:   9%|8         | 52/600 [28:59<5:05:31, 33.45s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0860, Learning rate: 1e-06:   9%|8         | 53/600 [28:59<4:59:12, 32.82s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.0926, Learning rate: 1e-06:   9%|8         | 53/600 [29:31<5:04:46, 33.43s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.0926, Learning rate: 1e-06:   9%|9         | 54/600 [29:31<4:58:34, 32.81s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0492, Learning rate: 1e-06:   9%|9         | 54/600 [30:04<5:04:07, 33.42s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0492, Learning rate: 1e-06:   9%|9         | 55/600 [30:04<4:58:02, 32.81s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1157, Learning rate: 1e-06:   9%|9         | 55/600 [30:37<5:03:28, 33.41s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1157, Learning rate: 1e-06:   9%|9         | 56/600 [30:37<4:57:30, 32.81s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.0649, Learning rate: 1e-06:   9%|9         | 56/600 [31:10<5:02:50, 33.40s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.0649, Learning rate: 1e-06:  10%|9         | 57/600 [31:10<4:56:58, 32.82s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1732, Learning rate: 1e-06:  10%|9         | 57/600 [31:43<5:02:15, 33.40s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1732, Learning rate: 1e-06:  10%|9         | 58/600 [31:43<4:56:30, 32.82s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0841, Learning rate: 1e-06:  10%|9         | 58/600 [32:16<5:01:32, 33.38s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0841, Learning rate: 1e-06:  10%|9         | 59/600 [32:16<4:55:52, 32.81s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0441, Learning rate: 1e-06:  10%|9         | 59/600 [32:48<5:00:53, 33.37s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0441, Learning rate: 1e-06:  10%|#         | 60/600 [32:48<4:55:20, 32.82s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1115, Learning rate: 1e-06:  10%|#         | 60/600 [33:22<5:00:20, 33.37s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1115, Learning rate: 1e-06:  10%|#         | 61/600 [33:22<4:54:51, 32.82s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1595, Learning rate: 1e-06:  10%|#         | 61/600 [33:54<4:59:39, 33.36s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1595, Learning rate: 1e-06:  10%|#         | 62/600 [33:54<4:54:16, 32.82s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0889, Learning rate: 1e-06:  10%|#         | 62/600 [34:27<4:58:59, 33.35s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0889, Learning rate: 1e-06:  10%|#         | 63/600 [34:27<4:53:42, 32.82s/it]Loss: 0.0102, L2-loss: 0.0096, KL: 6.1139, Learning rate: 1e-06:  10%|#         | 63/600 [35:00<4:58:21, 33.34s/it]Loss: 0.0102, L2-loss: 0.0096, KL: 6.1139, Learning rate: 1e-06:  11%|#         | 64/600 [35:00<4:53:08, 32.81s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1755, Learning rate: 1e-06:  11%|#         | 64/600 [35:33<4:57:46, 33.33s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1755, Learning rate: 1e-06:  11%|#         | 65/600 [35:33<4:52:39, 32.82s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1255, Learning rate: 1e-06:  11%|#         | 65/600 [36:06<4:57:09, 33.33s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1255, Learning rate: 1e-06:  11%|#1        | 66/600 [36:06<4:52:06, 32.82s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0958, Learning rate: 1e-06:  11%|#1        | 66/600 [36:38<4:56:27, 33.31s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0958, Learning rate: 1e-06:  11%|#1        | 67/600 [36:38<4:51:28, 32.81s/it]Loss: 0.0102, L2-loss: 0.0096, KL: 6.1698, Learning rate: 1e-06:  11%|#1        | 67/600 [37:11<4:55:51, 33.30s/it]Loss: 0.0102, L2-loss: 0.0096, KL: 6.1698, Learning rate: 1e-06:  11%|#1        | 68/600 [37:11<4:50:57, 32.82s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1877, Learning rate: 1e-06:  11%|#1        | 68/600 [37:44<4:55:13, 33.30s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1877, Learning rate: 1e-06:  12%|#1        | 69/600 [37:44<4:50:23, 32.81s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1699, Learning rate: 1e-06:  12%|#1        | 69/600 [38:16<4:54:34, 33.29s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1699, Learning rate: 1e-06:  12%|#1        | 70/600 [38:16<4:49:49, 32.81s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1065, Learning rate: 1e-06:  12%|#1        | 70/600 [38:49<4:53:58, 33.28s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1065, Learning rate: 1e-06:  12%|#1        | 71/600 [38:49<4:49:16, 32.81s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.0772, Learning rate: 1e-06:  12%|#1        | 71/600 [39:21<4:53:16, 33.26s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.0772, Learning rate: 1e-06:  12%|#2        | 72/600 [39:21<4:48:39, 32.80s/it]Loss: 0.0100, L2-loss: 0.0093, KL: 6.0845, Learning rate: 1e-06:  12%|#2        | 72/600 [39:54<4:52:42, 33.26s/it]Loss: 0.0100, L2-loss: 0.0093, KL: 6.0845, Learning rate: 1e-06:  12%|#2        | 73/600 [39:54<4:48:08, 32.81s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.0803, Learning rate: 1e-06:  12%|#2        | 73/600 [40:27<4:52:06, 33.26s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.0803, Learning rate: 1e-06:  12%|#2        | 74/600 [40:27<4:47:37, 32.81s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1470, Learning rate: 1e-06:  12%|#2        | 74/600 [41:00<4:51:26, 33.24s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1470, Learning rate: 1e-06:  12%|#2        | 75/600 [41:00<4:47:00, 32.80s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1533, Learning rate: 1e-06:  12%|#2        | 75/600 [41:33<4:50:51, 33.24s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1533, Learning rate: 1e-06:  13%|#2        | 76/600 [41:33<4:46:28, 32.80s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1952, Learning rate: 1e-07:  13%|#2        | 76/600 [42:05<4:50:11, 33.23s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1952, Learning rate: 1e-07:  13%|#2        | 77/600 [42:05<4:45:52, 32.80s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1064, Learning rate: 1e-07:  13%|#2        | 77/600 [42:38<4:49:34, 33.22s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1064, Learning rate: 1e-07:  13%|#3        | 78/600 [42:38<4:45:18, 32.79s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0689, Learning rate: 1e-07:  13%|#3        | 78/600 [43:10<4:48:54, 33.21s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0689, Learning rate: 1e-07:  13%|#3        | 79/600 [43:10<4:44:42, 32.79s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1477, Learning rate: 1e-07:  13%|#3        | 79/600 [43:43<4:48:18, 33.20s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1477, Learning rate: 1e-07:  13%|#3        | 80/600 [43:43<4:44:09, 32.79s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1050, Learning rate: 1e-07:  13%|#3        | 80/600 [44:15<4:47:40, 33.19s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1050, Learning rate: 1e-07:  14%|#3        | 81/600 [44:15<4:43:34, 32.78s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1384, Learning rate: 1e-07:  14%|#3        | 81/600 [44:48<4:47:04, 33.19s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1384, Learning rate: 1e-07:  14%|#3        | 82/600 [44:48<4:43:02, 32.78s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1507, Learning rate: 1e-07:  14%|#3        | 82/600 [45:20<4:46:26, 33.18s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1507, Learning rate: 1e-07:  14%|#3        | 83/600 [45:20<4:42:26, 32.78s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1049, Learning rate: 1e-07:  14%|#3        | 83/600 [45:53<4:45:52, 33.18s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1049, Learning rate: 1e-07:  14%|#4        | 84/600 [45:53<4:41:55, 32.78s/it]Loss: 0.0098, L2-loss: 0.0092, KL: 6.0275, Learning rate: 1e-07:  14%|#4        | 84/600 [46:26<4:45:16, 33.17s/it]Loss: 0.0098, L2-loss: 0.0092, KL: 6.0275, Learning rate: 1e-07:  14%|#4        | 85/600 [46:26<4:41:21, 32.78s/it]Loss: 0.0101, L2-loss: 0.0094, KL: 6.1403, Learning rate: 1e-07:  14%|#4        | 85/600 [46:58<4:44:38, 33.16s/it]Loss: 0.0101, L2-loss: 0.0094, KL: 6.1403, Learning rate: 1e-07:  14%|#4        | 86/600 [46:58<4:40:47, 32.78s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1400, Learning rate: 1e-07:  14%|#4        | 86/600 [47:31<4:44:02, 33.16s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1400, Learning rate: 1e-07:  14%|#4        | 87/600 [47:31<4:40:13, 32.78s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1309, Learning rate: 1e-07:  14%|#4        | 87/600 [48:04<4:43:28, 33.15s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1309, Learning rate: 1e-07:  15%|#4        | 88/600 [48:04<4:39:42, 32.78s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1596, Learning rate: 1e-07:  15%|#4        | 88/600 [48:37<4:42:52, 33.15s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1596, Learning rate: 1e-07:  15%|#4        | 89/600 [48:37<4:39:09, 32.78s/it]Loss: 0.0101, L2-loss: 0.0094, KL: 6.0800, Learning rate: 1e-07:  15%|#4        | 89/600 [49:09<4:42:12, 33.14s/it]Loss: 0.0101, L2-loss: 0.0094, KL: 6.0800, Learning rate: 1e-07:  15%|#5        | 90/600 [49:09<4:38:31, 32.77s/it]Loss: 0.0102, L2-loss: 0.0096, KL: 6.2104, Learning rate: 1e-07:  15%|#5        | 90/600 [49:42<4:41:38, 33.13s/it]Loss: 0.0102, L2-loss: 0.0096, KL: 6.2104, Learning rate: 1e-07:  15%|#5        | 91/600 [49:42<4:38:00, 32.77s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1147, Learning rate: 1e-07:  15%|#5        | 91/600 [50:14<4:41:02, 33.13s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1147, Learning rate: 1e-07:  15%|#5        | 92/600 [50:14<4:37:26, 32.77s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1057, Learning rate: 1e-07:  15%|#5        | 92/600 [50:47<4:40:28, 33.13s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1057, Learning rate: 1e-07:  16%|#5        | 93/600 [50:47<4:36:54, 32.77s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1406, Learning rate: 1e-07:  16%|#5        | 93/600 [51:19<4:39:50, 33.12s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1406, Learning rate: 1e-07:  16%|#5        | 94/600 [51:19<4:36:18, 32.76s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0831, Learning rate: 1e-07:  16%|#5        | 94/600 [51:52<4:39:15, 33.11s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0831, Learning rate: 1e-07:  16%|#5        | 95/600 [51:52<4:35:46, 32.77s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1297, Learning rate: 1e-07:  16%|#5        | 95/600 [52:25<4:38:40, 33.11s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1297, Learning rate: 1e-07:  16%|#6        | 96/600 [52:25<4:35:13, 32.77s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1047, Learning rate: 1e-07:  16%|#6        | 96/600 [52:58<4:38:05, 33.11s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1047, Learning rate: 1e-07:  16%|#6        | 97/600 [52:58<4:34:40, 32.76s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1515, Learning rate: 1e-07:  16%|#6        | 97/600 [53:30<4:37:30, 33.10s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1515, Learning rate: 1e-07:  16%|#6        | 98/600 [53:30<4:34:07, 32.76s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0741, Learning rate: 1e-07:  16%|#6        | 98/600 [54:03<4:36:56, 33.10s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0741, Learning rate: 1e-07:  16%|#6        | 99/600 [54:03<4:33:35, 32.77s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1596, Learning rate: 1e-07:  16%|#6        | 99/600 [54:36<4:36:23, 33.10s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1596, Learning rate: 1e-07:  17%|#6        | 100/600 [54:36<4:33:04, 32.77s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.1007, Learning rate: 1e-07:  17%|#6        | 100/600 [55:09<4:35:48, 33.10s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.1007, Learning rate: 1e-07:  17%|#6        | 101/600 [55:09<4:32:32, 32.77s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1196, Learning rate: 1e-07:  17%|#6        | 101/600 [55:41<4:35:10, 33.09s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1196, Learning rate: 1e-07:  17%|#7        | 102/600 [55:41<4:31:55, 32.76s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0975, Learning rate: 1e-08:  17%|#7        | 102/600 [56:14<4:34:35, 33.08s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0975, Learning rate: 1e-08:  17%|#7        | 103/600 [56:14<4:31:22, 32.76s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1143, Learning rate: 1e-08:  17%|#7        | 103/600 [56:47<4:33:59, 33.08s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1143, Learning rate: 1e-08:  17%|#7        | 104/600 [56:47<4:30:49, 32.76s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0617, Learning rate: 1e-08:  17%|#7        | 104/600 [57:19<4:33:25, 33.08s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0617, Learning rate: 1e-08:  18%|#7        | 105/600 [57:19<4:30:16, 32.76s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1469, Learning rate: 1e-08:  18%|#7        | 105/600 [57:51<4:32:47, 33.06s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1469, Learning rate: 1e-08:  18%|#7        | 106/600 [57:51<4:29:39, 32.75s/it]Loss: 0.0101, L2-loss: 0.0094, KL: 6.1742, Learning rate: 1e-08:  18%|#7        | 106/600 [58:24<4:32:14, 33.07s/it]Loss: 0.0101, L2-loss: 0.0094, KL: 6.1742, Learning rate: 1e-08:  18%|#7        | 107/600 [58:24<4:29:08, 32.76s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1234, Learning rate: 1e-08:  18%|#7        | 107/600 [58:57<4:31:39, 33.06s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1234, Learning rate: 1e-08:  18%|#8        | 108/600 [58:57<4:28:35, 32.76s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1381, Learning rate: 1e-08:  18%|#8        | 108/600 [59:30<4:31:03, 33.06s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1381, Learning rate: 1e-08:  18%|#8        | 109/600 [59:30<4:28:01, 32.75s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1135, Learning rate: 1e-08:  18%|#8        | 109/600 [1:00:02<4:30:29, 33.05s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1135, Learning rate: 1e-08:  18%|#8        | 110/600 [1:00:02<4:27:29, 32.75s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1991, Learning rate: 1e-08:  18%|#8        | 110/600 [1:00:35<4:29:54, 33.05s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1991, Learning rate: 1e-08:  18%|#8        | 111/600 [1:00:35<4:26:56, 32.75s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1910, Learning rate: 1e-08:  18%|#8        | 111/600 [1:01:08<4:29:23, 33.05s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1910, Learning rate: 1e-08:  19%|#8        | 112/600 [1:01:08<4:26:25, 32.76s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1027, Learning rate: 1e-08:  19%|#8        | 112/600 [1:01:41<4:28:49, 33.05s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1027, Learning rate: 1e-08:  19%|#8        | 113/600 [1:01:41<4:25:54, 32.76s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1550, Learning rate: 1e-08:  19%|#8        | 113/600 [1:02:15<4:28:17, 33.05s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1550, Learning rate: 1e-08:  19%|#9        | 114/600 [1:02:15<4:25:23, 32.76s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.0660, Learning rate: 1e-08:  19%|#9        | 114/600 [1:02:47<4:27:43, 33.05s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.0660, Learning rate: 1e-08:  19%|#9        | 115/600 [1:02:47<4:24:50, 32.76s/it]Loss: 0.0098, L2-loss: 0.0092, KL: 6.0618, Learning rate: 1e-08:  19%|#9        | 115/600 [1:03:20<4:27:09, 33.05s/it]Loss: 0.0098, L2-loss: 0.0092, KL: 6.0618, Learning rate: 1e-08:  19%|#9        | 116/600 [1:03:20<4:24:18, 32.76s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1596, Learning rate: 1e-08:  19%|#9        | 116/600 [1:03:53<4:26:35, 33.05s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1596, Learning rate: 1e-08:  20%|#9        | 117/600 [1:03:53<4:23:45, 32.77s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.2236, Learning rate: 1e-08:  20%|#9        | 117/600 [1:04:25<4:25:55, 33.04s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.2236, Learning rate: 1e-08:  20%|#9        | 118/600 [1:04:25<4:23:08, 32.76s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1401, Learning rate: 1e-08:  20%|#9        | 118/600 [1:04:56<4:25:16, 33.02s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1401, Learning rate: 1e-08:  20%|#9        | 119/600 [1:04:56<4:22:29, 32.74s/it]Loss: 0.0102, L2-loss: 0.0096, KL: 6.1751, Learning rate: 1e-08:  20%|#9        | 119/600 [1:05:27<4:24:36, 33.01s/it]Loss: 0.0102, L2-loss: 0.0096, KL: 6.1751, Learning rate: 1e-08:  20%|##        | 120/600 [1:05:27<4:21:51, 32.73s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1194, Learning rate: 1e-08:  20%|##        | 120/600 [1:05:59<4:23:57, 33.00s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1194, Learning rate: 1e-08:  20%|##        | 121/600 [1:05:59<4:21:14, 32.72s/it]Loss: 0.0101, L2-loss: 0.0094, KL: 6.1536, Learning rate: 1e-08:  20%|##        | 121/600 [1:06:31<4:23:19, 32.98s/it]Loss: 0.0101, L2-loss: 0.0094, KL: 6.1536, Learning rate: 1e-08:  20%|##        | 122/600 [1:06:31<4:20:37, 32.71s/it]Loss: 0.0101, L2-loss: 0.0094, KL: 6.1967, Learning rate: 1e-08:  20%|##        | 122/600 [1:07:02<4:22:40, 32.97s/it]Loss: 0.0101, L2-loss: 0.0094, KL: 6.1967, Learning rate: 1e-08:  20%|##        | 123/600 [1:07:02<4:19:59, 32.70s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1518, Learning rate: 1e-08:  20%|##        | 123/600 [1:07:33<4:22:01, 32.96s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1518, Learning rate: 1e-08:  21%|##        | 124/600 [1:07:33<4:19:21, 32.69s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0773, Learning rate: 1e-08:  21%|##        | 124/600 [1:08:05<4:21:22, 32.95s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0773, Learning rate: 1e-08:  21%|##        | 125/600 [1:08:05<4:18:44, 32.68s/it]Loss: 0.0101, L2-loss: 0.0094, KL: 6.1456, Learning rate: 1e-08:  21%|##        | 125/600 [1:08:36<4:20:43, 32.93s/it]Loss: 0.0101, L2-loss: 0.0094, KL: 6.1456, Learning rate: 1e-08:  21%|##1       | 126/600 [1:08:36<4:18:06, 32.67s/it]Loss: 0.0102, L2-loss: 0.0096, KL: 6.1283, Learning rate: 1e-08:  21%|##1       | 126/600 [1:09:08<4:20:05, 32.92s/it]Loss: 0.0102, L2-loss: 0.0096, KL: 6.1283, Learning rate: 1e-08:  21%|##1       | 127/600 [1:09:08<4:17:29, 32.66s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.0878, Learning rate: 1e-08:  21%|##1       | 127/600 [1:09:39<4:19:27, 32.91s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.0878, Learning rate: 1e-08:  21%|##1       | 128/600 [1:09:39<4:16:53, 32.66s/it]Loss: 0.0100, L2-loss: 0.0093, KL: 6.1128, Learning rate: 1e-08:  21%|##1       | 128/600 [1:10:11<4:18:49, 32.90s/it]Loss: 0.0100, L2-loss: 0.0093, KL: 6.1128, Learning rate: 1e-08:  22%|##1       | 129/600 [1:10:11<4:16:16, 32.65s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1444, Learning rate: 1e-08:  22%|##1       | 129/600 [1:10:42<4:18:10, 32.89s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1444, Learning rate: 1e-08:  22%|##1       | 130/600 [1:10:42<4:15:38, 32.64s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1450, Learning rate: 1e-08:  22%|##1       | 130/600 [1:11:14<4:17:33, 32.88s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1450, Learning rate: 1e-08:  22%|##1       | 131/600 [1:11:14<4:15:02, 32.63s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1002, Learning rate: 1e-08:  22%|##1       | 131/600 [1:11:45<4:16:55, 32.87s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1002, Learning rate: 1e-08:  22%|##2       | 132/600 [1:11:45<4:14:26, 32.62s/it]Loss: 0.0102, L2-loss: 0.0095, KL: 6.2308, Learning rate: 1e-08:  22%|##2       | 132/600 [1:12:17<4:16:17, 32.86s/it]Loss: 0.0102, L2-loss: 0.0095, KL: 6.2308, Learning rate: 1e-08:  22%|##2       | 133/600 [1:12:17<4:13:49, 32.61s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1968, Learning rate: 1e-08:  22%|##2       | 133/600 [1:12:48<4:15:40, 32.85s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1968, Learning rate: 1e-08:  22%|##2       | 134/600 [1:12:48<4:13:13, 32.60s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1488, Learning rate: 1e-08:  22%|##2       | 134/600 [1:13:20<4:15:03, 32.84s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1488, Learning rate: 1e-08:  22%|##2       | 135/600 [1:13:20<4:12:37, 32.60s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1159, Learning rate: 1e-08:  22%|##2       | 135/600 [1:13:51<4:14:25, 32.83s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1159, Learning rate: 1e-08:  23%|##2       | 136/600 [1:13:51<4:12:00, 32.59s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1976, Learning rate: 1e-08:  23%|##2       | 136/600 [1:14:23<4:13:47, 32.82s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1976, Learning rate: 1e-08:  23%|##2       | 137/600 [1:14:23<4:11:24, 32.58s/it]Loss: 0.0101, L2-loss: 0.0094, KL: 6.1972, Learning rate: 1e-08:  23%|##2       | 137/600 [1:14:54<4:13:10, 32.81s/it]Loss: 0.0101, L2-loss: 0.0094, KL: 6.1972, Learning rate: 1e-08:  23%|##3       | 138/600 [1:14:54<4:10:48, 32.57s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.2053, Learning rate: 1e-08:  23%|##3       | 138/600 [1:15:26<4:12:33, 32.80s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.2053, Learning rate: 1e-08:  23%|##3       | 139/600 [1:15:26<4:10:11, 32.56s/it]Loss: 0.0102, L2-loss: 0.0096, KL: 6.1949, Learning rate: 1e-08:  23%|##3       | 139/600 [1:15:57<4:11:56, 32.79s/it]Loss: 0.0102, L2-loss: 0.0096, KL: 6.1949, Learning rate: 1e-08:  23%|##3       | 140/600 [1:15:57<4:09:36, 32.56s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1486, Learning rate: 1e-08:  23%|##3       | 140/600 [1:16:29<4:11:19, 32.78s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1486, Learning rate: 1e-08:  24%|##3       | 141/600 [1:16:29<4:08:59, 32.55s/it]Loss: 0.0102, L2-loss: 0.0095, KL: 6.1914, Learning rate: 1e-08:  24%|##3       | 141/600 [1:17:00<4:10:42, 32.77s/it]Loss: 0.0102, L2-loss: 0.0095, KL: 6.1914, Learning rate: 1e-08:  24%|##3       | 142/600 [1:17:00<4:08:24, 32.54s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.0236, Learning rate: 1e-08:  24%|##3       | 142/600 [1:17:32<4:10:05, 32.76s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.0236, Learning rate: 1e-08:  24%|##3       | 143/600 [1:17:32<4:07:48, 32.53s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1225, Learning rate: 1e-08:  24%|##3       | 143/600 [1:18:04<4:09:29, 32.76s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1225, Learning rate: 1e-08:  24%|##4       | 144/600 [1:18:04<4:07:12, 32.53s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1533, Learning rate: 1e-08:  24%|##4       | 144/600 [1:18:35<4:08:52, 32.75s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1533, Learning rate: 1e-08:  24%|##4       | 145/600 [1:18:35<4:06:36, 32.52s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1078, Learning rate: 1e-08:  24%|##4       | 145/600 [1:19:06<4:08:14, 32.74s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1078, Learning rate: 1e-08:  24%|##4       | 146/600 [1:19:06<4:06:00, 32.51s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.2284, Learning rate: 1e-08:  24%|##4       | 146/600 [1:19:38<4:07:38, 32.73s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.2284, Learning rate: 1e-08:  24%|##4       | 147/600 [1:19:38<4:05:24, 32.50s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1447, Learning rate: 1e-08:  24%|##4       | 147/600 [1:20:09<4:07:01, 32.72s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1447, Learning rate: 1e-08:  25%|##4       | 148/600 [1:20:09<4:04:48, 32.50s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1405, Learning rate: 1e-08:  25%|##4       | 148/600 [1:20:40<4:06:24, 32.71s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1405, Learning rate: 1e-08:  25%|##4       | 149/600 [1:20:40<4:04:12, 32.49s/it]Loss: 0.0099, L2-loss: 0.0092, KL: 6.0932, Learning rate: 1e-08:  25%|##4       | 149/600 [1:21:12<4:05:48, 32.70s/it]Loss: 0.0099, L2-loss: 0.0092, KL: 6.0932, Learning rate: 1e-08:  25%|##5       | 150/600 [1:21:12<4:03:37, 32.48s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0615, Learning rate: 1e-08:  25%|##5       | 150/600 [1:21:43<4:05:11, 32.69s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0615, Learning rate: 1e-08:  25%|##5       | 151/600 [1:21:43<4:03:01, 32.48s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1749, Learning rate: 1e-08:  25%|##5       | 151/600 [1:22:15<4:04:36, 32.69s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1749, Learning rate: 1e-08:  25%|##5       | 152/600 [1:22:15<4:02:27, 32.47s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1691, Learning rate: 1e-08:  25%|##5       | 152/600 [1:22:47<4:03:59, 32.68s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1691, Learning rate: 1e-08:  26%|##5       | 153/600 [1:22:47<4:01:51, 32.46s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.1091, Learning rate: 1e-08:  26%|##5       | 153/600 [1:23:18<4:03:23, 32.67s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.1091, Learning rate: 1e-08:  26%|##5       | 154/600 [1:23:18<4:01:16, 32.46s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.0959, Learning rate: 1e-08:  26%|##5       | 154/600 [1:23:50<4:02:48, 32.66s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.0959, Learning rate: 1e-08:  26%|##5       | 155/600 [1:23:50<4:00:41, 32.45s/it]Loss: 0.0100, L2-loss: 0.0093, KL: 6.0281, Learning rate: 1e-08:  26%|##5       | 155/600 [1:24:21<4:02:12, 32.66s/it]Loss: 0.0100, L2-loss: 0.0093, KL: 6.0281, Learning rate: 1e-08:  26%|##6       | 156/600 [1:24:21<4:00:07, 32.45s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.0605, Learning rate: 1e-08:  26%|##6       | 156/600 [1:24:53<4:01:36, 32.65s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.0605, Learning rate: 1e-08:  26%|##6       | 157/600 [1:24:53<3:59:31, 32.44s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1722, Learning rate: 1e-08:  26%|##6       | 157/600 [1:25:24<4:01:00, 32.64s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1722, Learning rate: 1e-08:  26%|##6       | 158/600 [1:25:24<3:58:56, 32.43s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0526, Learning rate: 1e-08:  26%|##6       | 158/600 [1:25:56<4:00:24, 32.63s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0526, Learning rate: 1e-08:  26%|##6       | 159/600 [1:25:56<3:58:21, 32.43s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1138, Learning rate: 1e-08:  26%|##6       | 159/600 [1:26:27<3:59:48, 32.63s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1138, Learning rate: 1e-08:  27%|##6       | 160/600 [1:26:27<3:57:46, 32.42s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1462, Learning rate: 1e-08:  27%|##6       | 160/600 [1:26:59<3:59:12, 32.62s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1462, Learning rate: 1e-08:  27%|##6       | 161/600 [1:26:59<3:57:11, 32.42s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1456, Learning rate: 1e-08:  27%|##6       | 161/600 [1:27:30<3:58:37, 32.61s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1456, Learning rate: 1e-08:  27%|##7       | 162/600 [1:27:30<3:56:36, 32.41s/it]Loss: 0.0102, L2-loss: 0.0095, KL: 6.1928, Learning rate: 1e-08:  27%|##7       | 162/600 [1:28:02<3:58:01, 32.61s/it]Loss: 0.0102, L2-loss: 0.0095, KL: 6.1928, Learning rate: 1e-08:  27%|##7       | 163/600 [1:28:02<3:56:01, 32.41s/it]Loss: 0.0100, L2-loss: 0.0093, KL: 6.1144, Learning rate: 1e-08:  27%|##7       | 163/600 [1:28:33<3:57:25, 32.60s/it]Loss: 0.0100, L2-loss: 0.0093, KL: 6.1144, Learning rate: 1e-08:  27%|##7       | 164/600 [1:28:33<3:55:26, 32.40s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1258, Learning rate: 1e-08:  27%|##7       | 164/600 [1:29:05<3:56:50, 32.59s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1258, Learning rate: 1e-08:  28%|##7       | 165/600 [1:29:05<3:54:51, 32.40s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.0929, Learning rate: 1e-08:  28%|##7       | 165/600 [1:29:36<3:56:14, 32.58s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.0929, Learning rate: 1e-08:  28%|##7       | 166/600 [1:29:36<3:54:16, 32.39s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0975, Learning rate: 1e-08:  28%|##7       | 166/600 [1:30:08<3:55:39, 32.58s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0975, Learning rate: 1e-08:  28%|##7       | 167/600 [1:30:08<3:53:41, 32.38s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.0528, Learning rate: 1e-08:  28%|##7       | 167/600 [1:30:39<3:55:03, 32.57s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.0528, Learning rate: 1e-08:  28%|##8       | 168/600 [1:30:39<3:53:07, 32.38s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1687, Learning rate: 1e-08:  28%|##8       | 168/600 [1:31:10<3:54:28, 32.57s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1687, Learning rate: 1e-08:  28%|##8       | 169/600 [1:31:10<3:52:32, 32.37s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1460, Learning rate: 1e-08:  28%|##8       | 169/600 [1:31:42<3:53:53, 32.56s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1460, Learning rate: 1e-08:  28%|##8       | 170/600 [1:31:42<3:51:58, 32.37s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1347, Learning rate: 1e-08:  28%|##8       | 170/600 [1:32:14<3:53:17, 32.55s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1347, Learning rate: 1e-08:  28%|##8       | 171/600 [1:32:14<3:51:23, 32.36s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.1139, Learning rate: 1e-08:  28%|##8       | 171/600 [1:32:45<3:52:42, 32.55s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.1139, Learning rate: 1e-08:  29%|##8       | 172/600 [1:32:45<3:50:49, 32.36s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1279, Learning rate: 1e-08:  29%|##8       | 172/600 [1:33:17<3:52:07, 32.54s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1279, Learning rate: 1e-08:  29%|##8       | 173/600 [1:33:17<3:50:14, 32.35s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0958, Learning rate: 1e-08:  29%|##8       | 173/600 [1:33:48<3:51:32, 32.54s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0958, Learning rate: 1e-08:  29%|##9       | 174/600 [1:33:48<3:49:40, 32.35s/it]Loss: 0.0102, L2-loss: 0.0095, KL: 6.2001, Learning rate: 1e-08:  29%|##9       | 174/600 [1:34:20<3:50:58, 32.53s/it]Loss: 0.0102, L2-loss: 0.0095, KL: 6.2001, Learning rate: 1e-08:  29%|##9       | 175/600 [1:34:20<3:49:06, 32.35s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.1367, Learning rate: 1e-08:  29%|##9       | 175/600 [1:34:51<3:50:23, 32.53s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.1367, Learning rate: 1e-08:  29%|##9       | 176/600 [1:34:51<3:48:32, 32.34s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.0846, Learning rate: 1e-08:  29%|##9       | 176/600 [1:35:23<3:49:48, 32.52s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.0846, Learning rate: 1e-08:  30%|##9       | 177/600 [1:35:23<3:47:57, 32.34s/it]Loss: 0.0101, L2-loss: 0.0094, KL: 6.1241, Learning rate: 1e-08:  30%|##9       | 177/600 [1:35:54<3:49:12, 32.51s/it]Loss: 0.0101, L2-loss: 0.0094, KL: 6.1241, Learning rate: 1e-08:  30%|##9       | 178/600 [1:35:54<3:47:23, 32.33s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.0401, Learning rate: 1e-08:  30%|##9       | 178/600 [1:36:26<3:48:38, 32.51s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.0401, Learning rate: 1e-08:  30%|##9       | 179/600 [1:36:26<3:46:49, 32.33s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1151, Learning rate: 1e-08:  30%|##9       | 179/600 [1:36:57<3:48:03, 32.50s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1151, Learning rate: 1e-08:  30%|###       | 180/600 [1:36:57<3:46:14, 32.32s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1151, Learning rate: 1e-08:  30%|###       | 180/600 [1:37:29<3:47:28, 32.50s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1151, Learning rate: 1e-08:  30%|###       | 181/600 [1:37:29<3:45:40, 32.32s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0593, Learning rate: 1e-08:  30%|###       | 181/600 [1:38:00<3:46:53, 32.49s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0593, Learning rate: 1e-08:  30%|###       | 182/600 [1:38:00<3:45:06, 32.31s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1792, Learning rate: 1e-08:  30%|###       | 182/600 [1:38:32<3:46:18, 32.48s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1792, Learning rate: 1e-08:  30%|###       | 183/600 [1:38:32<3:44:32, 32.31s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.0369, Learning rate: 1e-08:  30%|###       | 183/600 [1:39:03<3:45:43, 32.48s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.0369, Learning rate: 1e-08:  31%|###       | 184/600 [1:39:03<3:43:57, 32.30s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.0866, Learning rate: 1e-08:  31%|###       | 184/600 [1:39:35<3:45:09, 32.47s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.0866, Learning rate: 1e-08:  31%|###       | 185/600 [1:39:35<3:43:23, 32.30s/it]Loss: 0.0100, L2-loss: 0.0093, KL: 6.0703, Learning rate: 1e-08:  31%|###       | 185/600 [1:40:06<3:44:34, 32.47s/it]Loss: 0.0100, L2-loss: 0.0093, KL: 6.0703, Learning rate: 1e-08:  31%|###1      | 186/600 [1:40:06<3:42:49, 32.29s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1050, Learning rate: 1e-08:  31%|###1      | 186/600 [1:40:38<3:44:00, 32.46s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1050, Learning rate: 1e-08:  31%|###1      | 187/600 [1:40:38<3:42:16, 32.29s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1292, Learning rate: 1e-08:  31%|###1      | 187/600 [1:41:09<3:43:25, 32.46s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1292, Learning rate: 1e-08:  31%|###1      | 188/600 [1:41:09<3:41:41, 32.29s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1344, Learning rate: 1e-08:  31%|###1      | 188/600 [1:41:41<3:42:50, 32.45s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1344, Learning rate: 1e-08:  32%|###1      | 189/600 [1:41:41<3:41:07, 32.28s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1267, Learning rate: 1e-08:  32%|###1      | 189/600 [1:42:12<3:42:16, 32.45s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1267, Learning rate: 1e-08:  32%|###1      | 190/600 [1:42:12<3:40:33, 32.28s/it]Loss: 0.0102, L2-loss: 0.0095, KL: 6.1990, Learning rate: 1e-08:  32%|###1      | 190/600 [1:42:44<3:41:41, 32.44s/it]Loss: 0.0102, L2-loss: 0.0095, KL: 6.1990, Learning rate: 1e-08:  32%|###1      | 191/600 [1:42:44<3:39:59, 32.27s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1663, Learning rate: 1e-08:  32%|###1      | 191/600 [1:43:15<3:41:07, 32.44s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1663, Learning rate: 1e-08:  32%|###2      | 192/600 [1:43:15<3:39:26, 32.27s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1435, Learning rate: 1e-08:  32%|###2      | 192/600 [1:43:47<3:40:32, 32.43s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1435, Learning rate: 1e-08:  32%|###2      | 193/600 [1:43:47<3:38:52, 32.27s/it]Loss: 0.0101, L2-loss: 0.0094, KL: 6.0907, Learning rate: 1e-08:  32%|###2      | 193/600 [1:44:18<3:39:58, 32.43s/it]Loss: 0.0101, L2-loss: 0.0094, KL: 6.0907, Learning rate: 1e-08:  32%|###2      | 194/600 [1:44:18<3:38:18, 32.26s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1046, Learning rate: 1e-08:  32%|###2      | 194/600 [1:44:49<3:39:23, 32.42s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1046, Learning rate: 1e-08:  32%|###2      | 195/600 [1:44:49<3:37:43, 32.26s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1782, Learning rate: 1e-08:  32%|###2      | 195/600 [1:45:21<3:38:48, 32.42s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1782, Learning rate: 1e-08:  33%|###2      | 196/600 [1:45:21<3:37:09, 32.25s/it]Loss: 0.0102, L2-loss: 0.0095, KL: 6.1412, Learning rate: 1e-08:  33%|###2      | 196/600 [1:45:52<3:38:14, 32.41s/it]Loss: 0.0102, L2-loss: 0.0095, KL: 6.1412, Learning rate: 1e-08:  33%|###2      | 197/600 [1:45:52<3:36:35, 32.25s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.1042, Learning rate: 1e-08:  33%|###2      | 197/600 [1:46:24<3:37:40, 32.41s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.1042, Learning rate: 1e-08:  33%|###3      | 198/600 [1:46:24<3:36:01, 32.24s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.0170, Learning rate: 1e-08:  33%|###3      | 198/600 [1:46:55<3:37:06, 32.40s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.0170, Learning rate: 1e-08:  33%|###3      | 199/600 [1:46:55<3:35:28, 32.24s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.2287, Learning rate: 1e-08:  33%|###3      | 199/600 [1:47:27<3:36:31, 32.40s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.2287, Learning rate: 1e-08:  33%|###3      | 200/600 [1:47:27<3:34:54, 32.24s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1524, Learning rate: 1e-08:  33%|###3      | 200/600 [1:47:58<3:35:57, 32.39s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1524, Learning rate: 1e-08:  34%|###3      | 201/600 [1:47:58<3:34:21, 32.23s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1074, Learning rate: 1e-08:  34%|###3      | 201/600 [1:48:30<3:35:23, 32.39s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1074, Learning rate: 1e-08:  34%|###3      | 202/600 [1:48:30<3:33:47, 32.23s/it]Loss: 0.0098, L2-loss: 0.0092, KL: 6.0256, Learning rate: 1e-08:  34%|###3      | 202/600 [1:49:01<3:34:49, 32.38s/it]Loss: 0.0098, L2-loss: 0.0092, KL: 6.0256, Learning rate: 1e-08:  34%|###3      | 203/600 [1:49:01<3:33:13, 32.23s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0905, Learning rate: 1e-08:  34%|###3      | 203/600 [1:49:33<3:34:14, 32.38s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0905, Learning rate: 1e-08:  34%|###4      | 204/600 [1:49:33<3:32:39, 32.22s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0317, Learning rate: 1e-08:  34%|###4      | 204/600 [1:50:04<3:33:40, 32.38s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0317, Learning rate: 1e-08:  34%|###4      | 205/600 [1:50:04<3:32:06, 32.22s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1863, Learning rate: 1e-08:  34%|###4      | 205/600 [1:50:36<3:33:06, 32.37s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1863, Learning rate: 1e-08:  34%|###4      | 206/600 [1:50:36<3:31:32, 32.21s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1775, Learning rate: 1e-08:  34%|###4      | 206/600 [1:51:07<3:32:32, 32.37s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1775, Learning rate: 1e-08:  34%|###4      | 207/600 [1:51:07<3:30:59, 32.21s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1014, Learning rate: 1e-08:  34%|###4      | 207/600 [1:51:39<3:31:58, 32.36s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1014, Learning rate: 1e-08:  35%|###4      | 208/600 [1:51:39<3:30:25, 32.21s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1673, Learning rate: 1e-08:  35%|###4      | 208/600 [1:52:10<3:31:24, 32.36s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1673, Learning rate: 1e-08:  35%|###4      | 209/600 [1:52:10<3:29:51, 32.20s/it]Loss: 0.0102, L2-loss: 0.0095, KL: 6.1714, Learning rate: 1e-08:  35%|###4      | 209/600 [1:52:41<3:30:49, 32.35s/it]Loss: 0.0102, L2-loss: 0.0095, KL: 6.1714, Learning rate: 1e-08:  35%|###5      | 210/600 [1:52:41<3:29:17, 32.20s/it]Loss: 0.0100, L2-loss: 0.0093, KL: 6.1442, Learning rate: 1e-08:  35%|###5      | 210/600 [1:53:13<3:30:15, 32.35s/it]Loss: 0.0100, L2-loss: 0.0093, KL: 6.1442, Learning rate: 1e-08:  35%|###5      | 211/600 [1:53:13<3:28:43, 32.19s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1562, Learning rate: 1e-08:  35%|###5      | 211/600 [1:53:44<3:29:41, 32.34s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1562, Learning rate: 1e-08:  35%|###5      | 212/600 [1:53:44<3:28:10, 32.19s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1342, Learning rate: 1e-08:  35%|###5      | 212/600 [1:54:16<3:29:08, 32.34s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1342, Learning rate: 1e-08:  36%|###5      | 213/600 [1:54:16<3:27:37, 32.19s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1490, Learning rate: 1e-08:  36%|###5      | 213/600 [1:54:47<3:28:34, 32.34s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1490, Learning rate: 1e-08:  36%|###5      | 214/600 [1:54:47<3:27:03, 32.19s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1186, Learning rate: 1e-08:  36%|###5      | 214/600 [1:55:19<3:28:00, 32.33s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1186, Learning rate: 1e-08:  36%|###5      | 215/600 [1:55:19<3:26:30, 32.18s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1040, Learning rate: 1e-08:  36%|###5      | 215/600 [1:55:51<3:27:27, 32.33s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1040, Learning rate: 1e-08:  36%|###6      | 216/600 [1:55:51<3:25:57, 32.18s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1192, Learning rate: 1e-08:  36%|###6      | 216/600 [1:56:22<3:26:53, 32.33s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1192, Learning rate: 1e-08:  36%|###6      | 217/600 [1:56:22<3:25:24, 32.18s/it]Loss: 0.0102, L2-loss: 0.0096, KL: 6.1748, Learning rate: 1e-08:  36%|###6      | 217/600 [1:56:53<3:26:19, 32.32s/it]Loss: 0.0102, L2-loss: 0.0096, KL: 6.1748, Learning rate: 1e-08:  36%|###6      | 218/600 [1:56:53<3:24:50, 32.17s/it]Loss: 0.0101, L2-loss: 0.0094, KL: 6.0914, Learning rate: 1e-08:  36%|###6      | 218/600 [1:57:25<3:25:45, 32.32s/it]Loss: 0.0101, L2-loss: 0.0094, KL: 6.0914, Learning rate: 1e-08:  36%|###6      | 219/600 [1:57:25<3:24:16, 32.17s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1388, Learning rate: 1e-08:  36%|###6      | 219/600 [1:57:56<3:25:12, 32.32s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1388, Learning rate: 1e-08:  37%|###6      | 220/600 [1:57:56<3:23:43, 32.17s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.1271, Learning rate: 1e-08:  37%|###6      | 220/600 [1:58:28<3:24:38, 32.31s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.1271, Learning rate: 1e-08:  37%|###6      | 221/600 [1:58:28<3:23:10, 32.16s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.0877, Learning rate: 1e-08:  37%|###6      | 221/600 [1:58:59<3:24:04, 32.31s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.0877, Learning rate: 1e-08:  37%|###7      | 222/600 [1:58:59<3:22:36, 32.16s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.0489, Learning rate: 1e-08:  37%|###7      | 222/600 [1:59:30<3:23:30, 32.30s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.0489, Learning rate: 1e-08:  37%|###7      | 223/600 [1:59:30<3:22:03, 32.16s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.2042, Learning rate: 1e-08:  37%|###7      | 223/600 [2:00:02<3:22:56, 32.30s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.2042, Learning rate: 1e-08:  37%|###7      | 224/600 [2:00:02<3:21:29, 32.15s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1903, Learning rate: 1e-08:  37%|###7      | 224/600 [2:00:34<3:22:22, 32.30s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1903, Learning rate: 1e-08:  38%|###7      | 225/600 [2:00:34<3:20:56, 32.15s/it]Loss: 0.0102, L2-loss: 0.0096, KL: 6.2068, Learning rate: 1e-08:  38%|###7      | 225/600 [2:01:05<3:21:49, 32.29s/it]Loss: 0.0102, L2-loss: 0.0096, KL: 6.2068, Learning rate: 1e-08:  38%|###7      | 226/600 [2:01:05<3:20:23, 32.15s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.0699, Learning rate: 1e-08:  38%|###7      | 226/600 [2:01:37<3:21:16, 32.29s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.0699, Learning rate: 1e-08:  38%|###7      | 227/600 [2:01:37<3:19:51, 32.15s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1902, Learning rate: 1e-08:  38%|###7      | 227/600 [2:02:09<3:20:43, 32.29s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1902, Learning rate: 1e-08:  38%|###8      | 228/600 [2:02:09<3:19:18, 32.15s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1854, Learning rate: 1e-08:  38%|###8      | 228/600 [2:02:40<3:20:09, 32.28s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1854, Learning rate: 1e-08:  38%|###8      | 229/600 [2:02:40<3:18:45, 32.14s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1073, Learning rate: 1e-08:  38%|###8      | 229/600 [2:03:12<3:19:36, 32.28s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1073, Learning rate: 1e-08:  38%|###8      | 230/600 [2:03:12<3:18:12, 32.14s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.0877, Learning rate: 1e-08:  38%|###8      | 230/600 [2:03:44<3:19:03, 32.28s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.0877, Learning rate: 1e-08:  38%|###8      | 231/600 [2:03:44<3:17:39, 32.14s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1346, Learning rate: 1e-08:  38%|###8      | 231/600 [2:04:15<3:18:29, 32.28s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1346, Learning rate: 1e-08:  39%|###8      | 232/600 [2:04:15<3:17:06, 32.14s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.0668, Learning rate: 1e-08:  39%|###8      | 232/600 [2:04:46<3:17:55, 32.27s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.0668, Learning rate: 1e-08:  39%|###8      | 233/600 [2:04:46<3:16:32, 32.13s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.1305, Learning rate: 1e-08:  39%|###8      | 233/600 [2:05:18<3:17:22, 32.27s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.1305, Learning rate: 1e-08:  39%|###9      | 234/600 [2:05:18<3:15:59, 32.13s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1451, Learning rate: 1e-08:  39%|###9      | 234/600 [2:05:50<3:16:49, 32.27s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1451, Learning rate: 1e-08:  39%|###9      | 235/600 [2:05:50<3:15:26, 32.13s/it]Loss: 0.0101, L2-loss: 0.0094, KL: 6.1682, Learning rate: 1e-08:  39%|###9      | 235/600 [2:06:21<3:16:15, 32.26s/it]Loss: 0.0101, L2-loss: 0.0094, KL: 6.1682, Learning rate: 1e-08:  39%|###9      | 236/600 [2:06:21<3:14:53, 32.13s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1707, Learning rate: 1e-08:  39%|###9      | 236/600 [2:06:52<3:15:42, 32.26s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1707, Learning rate: 1e-08:  40%|###9      | 237/600 [2:06:52<3:14:20, 32.12s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1739, Learning rate: 1e-08:  40%|###9      | 237/600 [2:07:24<3:15:08, 32.26s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1739, Learning rate: 1e-08:  40%|###9      | 238/600 [2:07:24<3:13:47, 32.12s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0745, Learning rate: 1e-08:  40%|###9      | 238/600 [2:07:56<3:14:35, 32.25s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0745, Learning rate: 1e-08:  40%|###9      | 239/600 [2:07:56<3:13:14, 32.12s/it]Loss: 0.0100, L2-loss: 0.0093, KL: 6.0982, Learning rate: 1e-08:  40%|###9      | 239/600 [2:08:27<3:14:02, 32.25s/it]Loss: 0.0100, L2-loss: 0.0093, KL: 6.0982, Learning rate: 1e-08:  40%|####      | 240/600 [2:08:27<3:12:41, 32.12s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1347, Learning rate: 1e-08:  40%|####      | 240/600 [2:08:59<3:13:29, 32.25s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1347, Learning rate: 1e-08:  40%|####      | 241/600 [2:08:59<3:12:08, 32.11s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0906, Learning rate: 1e-08:  40%|####      | 241/600 [2:09:30<3:12:55, 32.24s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0906, Learning rate: 1e-08:  40%|####      | 242/600 [2:09:30<3:11:35, 32.11s/it]Loss: 0.0099, L2-loss: 0.0092, KL: 6.1226, Learning rate: 1e-08:  40%|####      | 242/600 [2:10:02<3:12:22, 32.24s/it]Loss: 0.0099, L2-loss: 0.0092, KL: 6.1226, Learning rate: 1e-08:  40%|####      | 243/600 [2:10:02<3:11:03, 32.11s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1489, Learning rate: 1e-08:  40%|####      | 243/600 [2:10:34<3:11:49, 32.24s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1489, Learning rate: 1e-08:  41%|####      | 244/600 [2:10:34<3:10:30, 32.11s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.2019, Learning rate: 1e-08:  41%|####      | 244/600 [2:11:05<3:11:16, 32.24s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.2019, Learning rate: 1e-08:  41%|####      | 245/600 [2:11:05<3:09:57, 32.10s/it]Loss: 0.0102, L2-loss: 0.0096, KL: 6.2265, Learning rate: 1e-08:  41%|####      | 245/600 [2:11:37<3:10:43, 32.23s/it]Loss: 0.0102, L2-loss: 0.0096, KL: 6.2265, Learning rate: 1e-08:  41%|####1     | 246/600 [2:11:37<3:09:24, 32.10s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.0882, Learning rate: 1e-08:  41%|####1     | 246/600 [2:12:08<3:10:09, 32.23s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.0882, Learning rate: 1e-08:  41%|####1     | 247/600 [2:12:08<3:08:51, 32.10s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1621, Learning rate: 1e-08:  41%|####1     | 247/600 [2:12:40<3:09:36, 32.23s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1621, Learning rate: 1e-08:  41%|####1     | 248/600 [2:12:40<3:08:18, 32.10s/it]Loss: 0.0102, L2-loss: 0.0096, KL: 6.2315, Learning rate: 1e-08:  41%|####1     | 248/600 [2:13:12<3:09:03, 32.23s/it]Loss: 0.0102, L2-loss: 0.0096, KL: 6.2315, Learning rate: 1e-08:  42%|####1     | 249/600 [2:13:12<3:07:45, 32.10s/it]Loss: 0.0102, L2-loss: 0.0096, KL: 6.1731, Learning rate: 1e-08:  42%|####1     | 249/600 [2:13:43<3:08:30, 32.22s/it]Loss: 0.0102, L2-loss: 0.0096, KL: 6.1731, Learning rate: 1e-08:  42%|####1     | 250/600 [2:13:43<3:07:12, 32.09s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1440, Learning rate: 1e-08:  42%|####1     | 250/600 [2:14:14<3:07:56, 32.22s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1440, Learning rate: 1e-08:  42%|####1     | 251/600 [2:14:14<3:06:39, 32.09s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1669, Learning rate: 1e-08:  42%|####1     | 251/600 [2:14:46<3:07:24, 32.22s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1669, Learning rate: 1e-08:  42%|####2     | 252/600 [2:14:46<3:06:07, 32.09s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1100, Learning rate: 1e-08:  42%|####2     | 252/600 [2:15:18<3:06:50, 32.21s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1100, Learning rate: 1e-08:  42%|####2     | 253/600 [2:15:18<3:05:34, 32.09s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1256, Learning rate: 1e-08:  42%|####2     | 253/600 [2:15:49<3:06:17, 32.21s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1256, Learning rate: 1e-08:  42%|####2     | 254/600 [2:15:49<3:05:01, 32.09s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1086, Learning rate: 1e-08:  42%|####2     | 254/600 [2:16:21<3:05:44, 32.21s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1086, Learning rate: 1e-08:  42%|####2     | 255/600 [2:16:21<3:04:28, 32.08s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1652, Learning rate: 1e-08:  42%|####2     | 255/600 [2:16:52<3:05:11, 32.21s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1652, Learning rate: 1e-08:  43%|####2     | 256/600 [2:16:52<3:03:55, 32.08s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1299, Learning rate: 1e-08:  43%|####2     | 256/600 [2:17:24<3:04:37, 32.20s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1299, Learning rate: 1e-08:  43%|####2     | 257/600 [2:17:24<3:03:22, 32.08s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.0977, Learning rate: 1e-08:  43%|####2     | 257/600 [2:17:55<3:04:04, 32.20s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.0977, Learning rate: 1e-08:  43%|####3     | 258/600 [2:17:55<3:02:49, 32.08s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1781, Learning rate: 1e-08:  43%|####3     | 258/600 [2:18:27<3:03:31, 32.20s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1781, Learning rate: 1e-08:  43%|####3     | 259/600 [2:18:27<3:02:17, 32.07s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.0908, Learning rate: 1e-08:  43%|####3     | 259/600 [2:18:58<3:02:58, 32.20s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.0908, Learning rate: 1e-08:  43%|####3     | 260/600 [2:18:58<3:01:44, 32.07s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1689, Learning rate: 1e-08:  43%|####3     | 260/600 [2:19:30<3:02:25, 32.19s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1689, Learning rate: 1e-08:  44%|####3     | 261/600 [2:19:30<3:01:11, 32.07s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0557, Learning rate: 1e-08:  44%|####3     | 261/600 [2:20:01<3:01:52, 32.19s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0557, Learning rate: 1e-08:  44%|####3     | 262/600 [2:20:01<3:00:38, 32.07s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1646, Learning rate: 1e-08:  44%|####3     | 262/600 [2:20:33<3:01:19, 32.19s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1646, Learning rate: 1e-08:  44%|####3     | 263/600 [2:20:33<3:00:06, 32.07s/it]Loss: 0.0101, L2-loss: 0.0094, KL: 6.1626, Learning rate: 1e-08:  44%|####3     | 263/600 [2:21:04<3:00:46, 32.19s/it]Loss: 0.0101, L2-loss: 0.0094, KL: 6.1626, Learning rate: 1e-08:  44%|####4     | 264/600 [2:21:04<2:59:33, 32.06s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1760, Learning rate: 1e-08:  44%|####4     | 264/600 [2:21:36<3:00:13, 32.18s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1760, Learning rate: 1e-08:  44%|####4     | 265/600 [2:21:36<2:59:00, 32.06s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1945, Learning rate: 1e-08:  44%|####4     | 265/600 [2:22:07<2:59:40, 32.18s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1945, Learning rate: 1e-08:  44%|####4     | 266/600 [2:22:07<2:58:27, 32.06s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.0488, Learning rate: 1e-08:  44%|####4     | 266/600 [2:22:38<2:59:07, 32.18s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.0488, Learning rate: 1e-08:  44%|####4     | 267/600 [2:22:38<2:57:54, 32.06s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1703, Learning rate: 1e-08:  44%|####4     | 267/600 [2:23:10<2:58:33, 32.17s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1703, Learning rate: 1e-08:  45%|####4     | 268/600 [2:23:10<2:57:21, 32.05s/it]Loss: 0.0098, L2-loss: 0.0092, KL: 6.0214, Learning rate: 1e-08:  45%|####4     | 268/600 [2:23:41<2:58:00, 32.17s/it]Loss: 0.0098, L2-loss: 0.0092, KL: 6.0214, Learning rate: 1e-08:  45%|####4     | 269/600 [2:23:41<2:56:49, 32.05s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.0892, Learning rate: 1e-08:  45%|####4     | 269/600 [2:24:13<2:57:28, 32.17s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.0892, Learning rate: 1e-08:  45%|####5     | 270/600 [2:24:13<2:56:16, 32.05s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.1271, Learning rate: 1e-08:  45%|####5     | 270/600 [2:24:45<2:56:55, 32.17s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.1271, Learning rate: 1e-08:  45%|####5     | 271/600 [2:24:45<2:55:43, 32.05s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0700, Learning rate: 1e-08:  45%|####5     | 271/600 [2:25:16<2:56:22, 32.16s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0700, Learning rate: 1e-08:  45%|####5     | 272/600 [2:25:16<2:55:11, 32.05s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1420, Learning rate: 1e-08:  45%|####5     | 272/600 [2:25:48<2:55:49, 32.16s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1420, Learning rate: 1e-08:  46%|####5     | 273/600 [2:25:48<2:54:38, 32.05s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1635, Learning rate: 1e-08:  46%|####5     | 273/600 [2:26:19<2:55:16, 32.16s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1635, Learning rate: 1e-08:  46%|####5     | 274/600 [2:26:19<2:54:06, 32.04s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1416, Learning rate: 1e-08:  46%|####5     | 274/600 [2:26:51<2:54:43, 32.16s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1416, Learning rate: 1e-08:  46%|####5     | 275/600 [2:26:51<2:53:33, 32.04s/it]Loss: 0.0102, L2-loss: 0.0096, KL: 6.1421, Learning rate: 1e-08:  46%|####5     | 275/600 [2:27:22<2:54:10, 32.16s/it]Loss: 0.0102, L2-loss: 0.0096, KL: 6.1421, Learning rate: 1e-08:  46%|####6     | 276/600 [2:27:22<2:53:00, 32.04s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1103, Learning rate: 1e-08:  46%|####6     | 276/600 [2:27:54<2:53:37, 32.15s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1103, Learning rate: 1e-08:  46%|####6     | 277/600 [2:27:54<2:52:28, 32.04s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1931, Learning rate: 1e-08:  46%|####6     | 277/600 [2:28:26<2:53:04, 32.15s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1931, Learning rate: 1e-08:  46%|####6     | 278/600 [2:28:26<2:51:55, 32.04s/it]Loss: 0.0102, L2-loss: 0.0095, KL: 6.1756, Learning rate: 1e-08:  46%|####6     | 278/600 [2:28:57<2:52:31, 32.15s/it]Loss: 0.0102, L2-loss: 0.0095, KL: 6.1756, Learning rate: 1e-08:  46%|####6     | 279/600 [2:28:57<2:51:22, 32.03s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1514, Learning rate: 1e-08:  46%|####6     | 279/600 [2:29:29<2:51:59, 32.15s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1514, Learning rate: 1e-08:  47%|####6     | 280/600 [2:29:29<2:50:50, 32.03s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.2373, Learning rate: 1e-08:  47%|####6     | 280/600 [2:30:00<2:51:26, 32.15s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.2373, Learning rate: 1e-08:  47%|####6     | 281/600 [2:30:00<2:50:17, 32.03s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1609, Learning rate: 1e-08:  47%|####6     | 281/600 [2:30:32<2:50:53, 32.14s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1609, Learning rate: 1e-08:  47%|####6     | 282/600 [2:30:32<2:49:45, 32.03s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1545, Learning rate: 1e-08:  47%|####6     | 282/600 [2:31:04<2:50:21, 32.14s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1545, Learning rate: 1e-08:  47%|####7     | 283/600 [2:31:04<2:49:13, 32.03s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.2186, Learning rate: 1e-08:  47%|####7     | 283/600 [2:31:35<2:49:47, 32.14s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.2186, Learning rate: 1e-08:  47%|####7     | 284/600 [2:31:35<2:48:40, 32.03s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1927, Learning rate: 1e-08:  47%|####7     | 284/600 [2:32:06<2:49:14, 32.14s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1927, Learning rate: 1e-08:  48%|####7     | 285/600 [2:32:06<2:48:07, 32.02s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1499, Learning rate: 1e-08:  48%|####7     | 285/600 [2:32:38<2:48:42, 32.13s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1499, Learning rate: 1e-08:  48%|####7     | 286/600 [2:32:38<2:47:34, 32.02s/it]Loss: 0.0101, L2-loss: 0.0094, KL: 6.1529, Learning rate: 1e-08:  48%|####7     | 286/600 [2:33:09<2:48:09, 32.13s/it]Loss: 0.0101, L2-loss: 0.0094, KL: 6.1529, Learning rate: 1e-08:  48%|####7     | 287/600 [2:33:09<2:47:02, 32.02s/it]Loss: 0.0102, L2-loss: 0.0096, KL: 6.1460, Learning rate: 1e-08:  48%|####7     | 287/600 [2:33:41<2:47:36, 32.13s/it]Loss: 0.0102, L2-loss: 0.0096, KL: 6.1460, Learning rate: 1e-08:  48%|####8     | 288/600 [2:33:41<2:46:29, 32.02s/it]Loss: 0.0102, L2-loss: 0.0095, KL: 6.1750, Learning rate: 1e-08:  48%|####8     | 288/600 [2:34:12<2:47:03, 32.13s/it]Loss: 0.0102, L2-loss: 0.0095, KL: 6.1750, Learning rate: 1e-08:  48%|####8     | 289/600 [2:34:12<2:45:57, 32.02s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1170, Learning rate: 1e-08:  48%|####8     | 289/600 [2:34:44<2:46:31, 32.13s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1170, Learning rate: 1e-08:  48%|####8     | 290/600 [2:34:44<2:45:24, 32.01s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.2003, Learning rate: 1e-08:  48%|####8     | 290/600 [2:35:15<2:45:58, 32.12s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.2003, Learning rate: 1e-08:  48%|####8     | 291/600 [2:35:15<2:44:52, 32.01s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.0536, Learning rate: 1e-08:  48%|####8     | 291/600 [2:35:47<2:45:25, 32.12s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.0536, Learning rate: 1e-08:  49%|####8     | 292/600 [2:35:47<2:44:19, 32.01s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1640, Learning rate: 1e-08:  49%|####8     | 292/600 [2:36:18<2:44:52, 32.12s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1640, Learning rate: 1e-08:  49%|####8     | 293/600 [2:36:18<2:43:46, 32.01s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1583, Learning rate: 1e-08:  49%|####8     | 293/600 [2:36:49<2:44:19, 32.12s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1583, Learning rate: 1e-08:  49%|####9     | 294/600 [2:36:49<2:43:14, 32.01s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1878, Learning rate: 1e-08:  49%|####9     | 294/600 [2:37:21<2:43:46, 32.11s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1878, Learning rate: 1e-08:  49%|####9     | 295/600 [2:37:21<2:42:41, 32.00s/it]Loss: 0.0100, L2-loss: 0.0093, KL: 6.1514, Learning rate: 1e-08:  49%|####9     | 295/600 [2:37:53<2:43:14, 32.11s/it]Loss: 0.0100, L2-loss: 0.0093, KL: 6.1514, Learning rate: 1e-08:  49%|####9     | 296/600 [2:37:53<2:42:09, 32.00s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1136, Learning rate: 1e-08:  49%|####9     | 296/600 [2:38:24<2:42:41, 32.11s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1136, Learning rate: 1e-08:  50%|####9     | 297/600 [2:38:24<2:41:36, 32.00s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.1316, Learning rate: 1e-08:  50%|####9     | 297/600 [2:38:56<2:42:09, 32.11s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.1316, Learning rate: 1e-08:  50%|####9     | 298/600 [2:38:56<2:41:04, 32.00s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1841, Learning rate: 1e-08:  50%|####9     | 298/600 [2:39:27<2:41:36, 32.11s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1841, Learning rate: 1e-08:  50%|####9     | 299/600 [2:39:27<2:40:31, 32.00s/it]Loss: 0.0102, L2-loss: 0.0096, KL: 6.1504, Learning rate: 1e-08:  50%|####9     | 299/600 [2:39:59<2:41:03, 32.10s/it]Loss: 0.0102, L2-loss: 0.0096, KL: 6.1504, Learning rate: 1e-08:  50%|#####     | 300/600 [2:39:59<2:39:59, 32.00s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1167, Learning rate: 1e-08:  50%|#####     | 300/600 [2:40:30<2:40:30, 32.10s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1167, Learning rate: 1e-08:  50%|#####     | 301/600 [2:40:30<2:39:26, 32.00s/it]Loss: 0.0102, L2-loss: 0.0095, KL: 6.2149, Learning rate: 1e-08:  50%|#####     | 301/600 [2:41:02<2:39:58, 32.10s/it]Loss: 0.0102, L2-loss: 0.0095, KL: 6.2149, Learning rate: 1e-08:  50%|#####     | 302/600 [2:41:02<2:38:54, 31.99s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.1018, Learning rate: 1e-08:  50%|#####     | 302/600 [2:41:33<2:39:25, 32.10s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.1018, Learning rate: 1e-08:  50%|#####     | 303/600 [2:41:33<2:38:21, 31.99s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.2000, Learning rate: 1e-08:  50%|#####     | 303/600 [2:42:04<2:38:52, 32.10s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.2000, Learning rate: 1e-08:  51%|#####     | 304/600 [2:42:04<2:37:48, 31.99s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.2000, Learning rate: 1e-08:  51%|#####     | 304/600 [2:42:36<2:38:19, 32.09s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.2000, Learning rate: 1e-08:  51%|#####     | 305/600 [2:42:36<2:37:16, 31.99s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1110, Learning rate: 1e-08:  51%|#####     | 305/600 [2:43:08<2:37:47, 32.09s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1110, Learning rate: 1e-08:  51%|#####1    | 306/600 [2:43:08<2:36:44, 31.99s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1478, Learning rate: 1e-08:  51%|#####1    | 306/600 [2:43:39<2:37:14, 32.09s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1478, Learning rate: 1e-08:  51%|#####1    | 307/600 [2:43:39<2:36:11, 31.99s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1944, Learning rate: 1e-08:  51%|#####1    | 307/600 [2:44:10<2:36:41, 32.09s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1944, Learning rate: 1e-08:  51%|#####1    | 308/600 [2:44:10<2:35:39, 31.98s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.1105, Learning rate: 1e-08:  51%|#####1    | 308/600 [2:44:42<2:36:08, 32.08s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.1105, Learning rate: 1e-08:  52%|#####1    | 309/600 [2:44:42<2:35:06, 31.98s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1337, Learning rate: 1e-08:  52%|#####1    | 309/600 [2:45:13<2:35:35, 32.08s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1337, Learning rate: 1e-08:  52%|#####1    | 310/600 [2:45:13<2:34:33, 31.98s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1224, Learning rate: 1e-08:  52%|#####1    | 310/600 [2:45:44<2:35:03, 32.08s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1224, Learning rate: 1e-08:  52%|#####1    | 311/600 [2:45:44<2:34:01, 31.98s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1543, Learning rate: 1e-08:  52%|#####1    | 311/600 [2:46:16<2:34:30, 32.08s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1543, Learning rate: 1e-08:  52%|#####2    | 312/600 [2:46:16<2:33:28, 31.97s/it]Loss: 0.0102, L2-loss: 0.0096, KL: 6.2316, Learning rate: 1e-08:  52%|#####2    | 312/600 [2:46:47<2:33:57, 32.08s/it]Loss: 0.0102, L2-loss: 0.0096, KL: 6.2316, Learning rate: 1e-08:  52%|#####2    | 313/600 [2:46:47<2:32:56, 31.97s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1332, Learning rate: 1e-08:  52%|#####2    | 313/600 [2:47:19<2:33:25, 32.07s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1332, Learning rate: 1e-08:  52%|#####2    | 314/600 [2:47:19<2:32:23, 31.97s/it]Loss: 0.0101, L2-loss: 0.0094, KL: 6.1599, Learning rate: 1e-08:  52%|#####2    | 314/600 [2:47:50<2:32:52, 32.07s/it]Loss: 0.0101, L2-loss: 0.0094, KL: 6.1599, Learning rate: 1e-08:  52%|#####2    | 315/600 [2:47:50<2:31:51, 31.97s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.0905, Learning rate: 1e-08:  52%|#####2    | 315/600 [2:48:22<2:32:20, 32.07s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.0905, Learning rate: 1e-08:  53%|#####2    | 316/600 [2:48:22<2:31:19, 31.97s/it]Loss: 0.0102, L2-loss: 0.0096, KL: 6.2244, Learning rate: 1e-08:  53%|#####2    | 316/600 [2:48:53<2:31:47, 32.07s/it]Loss: 0.0102, L2-loss: 0.0096, KL: 6.2244, Learning rate: 1e-08:  53%|#####2    | 317/600 [2:48:53<2:30:46, 31.97s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.0065, Learning rate: 1e-08:  53%|#####2    | 317/600 [2:49:25<2:31:15, 32.07s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.0065, Learning rate: 1e-08:  53%|#####3    | 318/600 [2:49:25<2:30:14, 31.97s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1119, Learning rate: 1e-08:  53%|#####3    | 318/600 [2:49:56<2:30:42, 32.07s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1119, Learning rate: 1e-08:  53%|#####3    | 319/600 [2:49:56<2:29:42, 31.96s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0593, Learning rate: 1e-08:  53%|#####3    | 319/600 [2:50:28<2:30:09, 32.06s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0593, Learning rate: 1e-08:  53%|#####3    | 320/600 [2:50:28<2:29:09, 31.96s/it]Loss: 0.0101, L2-loss: 0.0094, KL: 6.1764, Learning rate: 1e-08:  53%|#####3    | 320/600 [2:51:00<2:29:37, 32.06s/it]Loss: 0.0101, L2-loss: 0.0094, KL: 6.1764, Learning rate: 1e-08:  54%|#####3    | 321/600 [2:51:00<2:28:37, 31.96s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.0702, Learning rate: 1e-08:  54%|#####3    | 321/600 [2:51:31<2:29:05, 32.06s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.0702, Learning rate: 1e-08:  54%|#####3    | 322/600 [2:51:31<2:28:05, 31.96s/it]Loss: 0.0101, L2-loss: 0.0094, KL: 6.1404, Learning rate: 1e-08:  54%|#####3    | 322/600 [2:52:03<2:28:32, 32.06s/it]Loss: 0.0101, L2-loss: 0.0094, KL: 6.1404, Learning rate: 1e-08:  54%|#####3    | 323/600 [2:52:03<2:27:33, 31.96s/it]Loss: 0.0099, L2-loss: 0.0092, KL: 6.0251, Learning rate: 1e-08:  54%|#####3    | 323/600 [2:52:34<2:28:00, 32.06s/it]Loss: 0.0099, L2-loss: 0.0092, KL: 6.0251, Learning rate: 1e-08:  54%|#####4    | 324/600 [2:52:34<2:27:00, 31.96s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1788, Learning rate: 1e-08:  54%|#####4    | 324/600 [2:53:06<2:27:27, 32.06s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1788, Learning rate: 1e-08:  54%|#####4    | 325/600 [2:53:06<2:26:28, 31.96s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1634, Learning rate: 1e-08:  54%|#####4    | 325/600 [2:53:37<2:26:54, 32.05s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1634, Learning rate: 1e-08:  54%|#####4    | 326/600 [2:53:37<2:25:55, 31.96s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1239, Learning rate: 1e-08:  54%|#####4    | 326/600 [2:54:08<2:26:22, 32.05s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1239, Learning rate: 1e-08:  55%|#####4    | 327/600 [2:54:08<2:25:23, 31.95s/it]Loss: 0.0102, L2-loss: 0.0096, KL: 6.2523, Learning rate: 1e-08:  55%|#####4    | 327/600 [2:54:40<2:25:49, 32.05s/it]Loss: 0.0102, L2-loss: 0.0096, KL: 6.2523, Learning rate: 1e-08:  55%|#####4    | 328/600 [2:54:40<2:24:51, 31.95s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1368, Learning rate: 1e-08:  55%|#####4    | 328/600 [2:55:11<2:25:17, 32.05s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1368, Learning rate: 1e-08:  55%|#####4    | 329/600 [2:55:11<2:24:18, 31.95s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.0633, Learning rate: 1e-08:  55%|#####4    | 329/600 [2:55:43<2:24:44, 32.05s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.0633, Learning rate: 1e-08:  55%|#####5    | 330/600 [2:55:43<2:23:46, 31.95s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0963, Learning rate: 1e-08:  55%|#####5    | 330/600 [2:56:14<2:24:12, 32.04s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0963, Learning rate: 1e-08:  55%|#####5    | 331/600 [2:56:14<2:23:13, 31.95s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1175, Learning rate: 1e-08:  55%|#####5    | 331/600 [2:56:46<2:23:39, 32.04s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1175, Learning rate: 1e-08:  55%|#####5    | 332/600 [2:56:46<2:22:41, 31.95s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.2529, Learning rate: 1e-08:  55%|#####5    | 332/600 [2:57:17<2:23:07, 32.04s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.2529, Learning rate: 1e-08:  56%|#####5    | 333/600 [2:57:17<2:22:09, 31.94s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.0927, Learning rate: 1e-08:  56%|#####5    | 333/600 [2:57:49<2:22:34, 32.04s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.0927, Learning rate: 1e-08:  56%|#####5    | 334/600 [2:57:49<2:21:37, 31.94s/it]Loss: 0.0102, L2-loss: 0.0095, KL: 6.2068, Learning rate: 1e-08:  56%|#####5    | 334/600 [2:58:20<2:22:02, 32.04s/it]Loss: 0.0102, L2-loss: 0.0095, KL: 6.2068, Learning rate: 1e-08:  56%|#####5    | 335/600 [2:58:20<2:21:04, 31.94s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1308, Learning rate: 1e-08:  56%|#####5    | 335/600 [2:58:52<2:21:29, 32.04s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1308, Learning rate: 1e-08:  56%|#####6    | 336/600 [2:58:52<2:20:32, 31.94s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1370, Learning rate: 1e-08:  56%|#####6    | 336/600 [2:59:23<2:20:57, 32.03s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1370, Learning rate: 1e-08:  56%|#####6    | 337/600 [2:59:23<2:20:00, 31.94s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1545, Learning rate: 1e-08:  56%|#####6    | 337/600 [2:59:54<2:20:24, 32.03s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1545, Learning rate: 1e-08:  56%|#####6    | 338/600 [2:59:54<2:19:27, 31.94s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1461, Learning rate: 1e-08:  56%|#####6    | 338/600 [3:00:26<2:19:52, 32.03s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1461, Learning rate: 1e-08:  56%|#####6    | 339/600 [3:00:26<2:18:55, 31.94s/it]Loss: 0.0101, L2-loss: 0.0094, KL: 6.2163, Learning rate: 1e-08:  56%|#####6    | 339/600 [3:00:58<2:19:19, 32.03s/it]Loss: 0.0101, L2-loss: 0.0094, KL: 6.2163, Learning rate: 1e-08:  57%|#####6    | 340/600 [3:00:58<2:18:23, 31.94s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1041, Learning rate: 1e-08:  57%|#####6    | 340/600 [3:01:29<2:18:47, 32.03s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1041, Learning rate: 1e-08:  57%|#####6    | 341/600 [3:01:29<2:17:51, 31.93s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1257, Learning rate: 1e-08:  57%|#####6    | 341/600 [3:02:01<2:18:14, 32.03s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1257, Learning rate: 1e-08:  57%|#####6    | 342/600 [3:02:01<2:17:18, 31.93s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1097, Learning rate: 1e-08:  57%|#####6    | 342/600 [3:02:32<2:17:42, 32.02s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1097, Learning rate: 1e-08:  57%|#####7    | 343/600 [3:02:32<2:16:46, 31.93s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1664, Learning rate: 1e-08:  57%|#####7    | 343/600 [3:03:04<2:17:10, 32.02s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1664, Learning rate: 1e-08:  57%|#####7    | 344/600 [3:03:04<2:16:14, 31.93s/it]Loss: 0.0098, L2-loss: 0.0092, KL: 6.0091, Learning rate: 1e-08:  57%|#####7    | 344/600 [3:03:35<2:16:37, 32.02s/it]Loss: 0.0098, L2-loss: 0.0092, KL: 6.0091, Learning rate: 1e-08:  57%|#####7    | 345/600 [3:03:35<2:15:42, 31.93s/it]Loss: 0.0100, L2-loss: 0.0093, KL: 6.1351, Learning rate: 1e-08:  57%|#####7    | 345/600 [3:04:07<2:16:05, 32.02s/it]Loss: 0.0100, L2-loss: 0.0093, KL: 6.1351, Learning rate: 1e-08:  58%|#####7    | 346/600 [3:04:07<2:15:09, 31.93s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.1362, Learning rate: 1e-08:  58%|#####7    | 346/600 [3:04:38<2:15:32, 32.02s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.1362, Learning rate: 1e-08:  58%|#####7    | 347/600 [3:04:38<2:14:37, 31.93s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.0893, Learning rate: 1e-08:  58%|#####7    | 347/600 [3:05:09<2:15:00, 32.02s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.0893, Learning rate: 1e-08:  58%|#####8    | 348/600 [3:05:09<2:14:05, 31.93s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1034, Learning rate: 1e-08:  58%|#####8    | 348/600 [3:05:41<2:14:28, 32.02s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1034, Learning rate: 1e-08:  58%|#####8    | 349/600 [3:05:41<2:13:33, 31.92s/it]Loss: 0.0100, L2-loss: 0.0093, KL: 6.1159, Learning rate: 1e-08:  58%|#####8    | 349/600 [3:06:13<2:13:55, 32.01s/it]Loss: 0.0100, L2-loss: 0.0093, KL: 6.1159, Learning rate: 1e-08:  58%|#####8    | 350/600 [3:06:13<2:13:00, 31.92s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1188, Learning rate: 1e-08:  58%|#####8    | 350/600 [3:06:44<2:13:23, 32.01s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1188, Learning rate: 1e-08:  58%|#####8    | 351/600 [3:06:44<2:12:28, 31.92s/it]Loss: 0.0101, L2-loss: 0.0094, KL: 6.1669, Learning rate: 1e-08:  58%|#####8    | 351/600 [3:07:16<2:12:51, 32.01s/it]Loss: 0.0101, L2-loss: 0.0094, KL: 6.1669, Learning rate: 1e-08:  59%|#####8    | 352/600 [3:07:16<2:11:56, 31.92s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1325, Learning rate: 1e-08:  59%|#####8    | 352/600 [3:07:47<2:12:18, 32.01s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1325, Learning rate: 1e-08:  59%|#####8    | 353/600 [3:07:47<2:11:24, 31.92s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0829, Learning rate: 1e-08:  59%|#####8    | 353/600 [3:08:19<2:11:46, 32.01s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0829, Learning rate: 1e-08:  59%|#####8    | 354/600 [3:08:19<2:10:52, 31.92s/it]Loss: 0.0102, L2-loss: 0.0095, KL: 6.2222, Learning rate: 1e-08:  59%|#####8    | 354/600 [3:08:50<2:11:13, 32.01s/it]Loss: 0.0102, L2-loss: 0.0095, KL: 6.2222, Learning rate: 1e-08:  59%|#####9    | 355/600 [3:08:50<2:10:19, 31.92s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0945, Learning rate: 1e-08:  59%|#####9    | 355/600 [3:09:22<2:10:41, 32.01s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0945, Learning rate: 1e-08:  59%|#####9    | 356/600 [3:09:22<2:09:47, 31.92s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1311, Learning rate: 1e-08:  59%|#####9    | 356/600 [3:09:53<2:10:09, 32.01s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1311, Learning rate: 1e-08:  60%|#####9    | 357/600 [3:09:53<2:09:15, 31.92s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0869, Learning rate: 1e-08:  60%|#####9    | 357/600 [3:10:25<2:09:36, 32.00s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0869, Learning rate: 1e-08:  60%|#####9    | 358/600 [3:10:25<2:08:43, 31.91s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1562, Learning rate: 1e-08:  60%|#####9    | 358/600 [3:10:57<2:09:04, 32.00s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1562, Learning rate: 1e-08:  60%|#####9    | 359/600 [3:10:57<2:08:11, 31.91s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1506, Learning rate: 1e-08:  60%|#####9    | 359/600 [3:11:28<2:08:32, 32.00s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1506, Learning rate: 1e-08:  60%|######    | 360/600 [3:11:28<2:07:39, 31.91s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1292, Learning rate: 1e-08:  60%|######    | 360/600 [3:12:00<2:08:00, 32.00s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1292, Learning rate: 1e-08:  60%|######    | 361/600 [3:12:00<2:07:07, 31.91s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1452, Learning rate: 1e-08:  60%|######    | 361/600 [3:12:32<2:07:28, 32.00s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1452, Learning rate: 1e-08:  60%|######    | 362/600 [3:12:32<2:06:35, 31.91s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0707, Learning rate: 1e-08:  60%|######    | 362/600 [3:13:03<2:06:55, 32.00s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.0707, Learning rate: 1e-08:  60%|######    | 363/600 [3:13:03<2:06:02, 31.91s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.0707, Learning rate: 1e-08:  60%|######    | 363/600 [3:13:35<2:06:23, 32.00s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.0707, Learning rate: 1e-08:  61%|######    | 364/600 [3:13:35<2:05:30, 31.91s/it]Loss: 0.0102, L2-loss: 0.0096, KL: 6.2333, Learning rate: 1e-08:  61%|######    | 364/600 [3:14:06<2:05:51, 32.00s/it]Loss: 0.0102, L2-loss: 0.0096, KL: 6.2333, Learning rate: 1e-08:  61%|######    | 365/600 [3:14:06<2:04:58, 31.91s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1595, Learning rate: 1e-08:  61%|######    | 365/600 [3:14:37<2:05:18, 31.99s/it]Loss: 0.0101, L2-loss: 0.0095, KL: 6.1595, Learning rate: 1e-08:  61%|######1   | 366/600 [3:14:37<2:04:26, 31.91s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1415, Learning rate: 1e-08:  61%|######1   | 366/600 [3:15:09<2:04:46, 31.99s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1415, Learning rate: 1e-08:  61%|######1   | 367/600 [3:15:09<2:03:54, 31.91s/it]Loss: 0.0100, L2-loss: 0.0093, KL: 6.1335, Learning rate: 1e-08:  61%|######1   | 367/600 [3:15:40<2:04:14, 31.99s/it]Loss: 0.0100, L2-loss: 0.0093, KL: 6.1335, Learning rate: 1e-08:  61%|######1   | 368/600 [3:15:40<2:03:21, 31.90s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.0791, Learning rate: 1e-08:  61%|######1   | 368/600 [3:16:12<2:03:41, 31.99s/it]Loss: 0.0099, L2-loss: 0.0093, KL: 6.0791, Learning rate: 1e-08:  62%|######1   | 369/600 [3:16:12<2:02:49, 31.90s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1673, Learning rate: 1e-08:  62%|######1   | 369/600 [3:16:44<2:03:09, 31.99s/it]Loss: 0.0100, L2-loss: 0.0094, KL: 6.1673, Learning rate: 1e-08:  62%|######1   | 370/600 [3:16:44<2:02:17, 31.90s/it]Traceback (most recent call last):
  File "main.py", line 21, in <module>
    x, x_org, nan = vae.train()
  File "/cluster/home/leoj/sandbox/vae.py", line 250, in train
    x, x_org = self._config.get_training_batch()
  File "/cluster/home/leoj/sandbox/results/0245/config.py", line 101, in get_training_batch
    originals = np.asarray(originals)
  File "/cluster/home/leoj/.virtualenvs/mp/lib/python2.7/site-packages/numpy/core/numeric.py", line 492, in asarray
    return array(a, dtype, copy=False, order=order)
KeyboardInterrupt
